<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Environmental Niche Modeling Workflow Based on dismo • modleR</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><meta property="og:title" content="Environmental Niche Modeling Workflow Based on dismo">
<meta property="og:description" content="This package implements a workflow to perform ecological niche modeling (ENM), including some procedures of data preparation and cleaning, the setup of several experimental designs (crossvalidation, repeated crossvalidation and bootstrap), the application of inclusion and exclusion buffers to background selection, fitting algorithms that are already implemented in dismo, randomForest, e1071, kernlab packages, namely: Bioclim, Domain, GLM, Mahalanobis Distance, Maxent, Random Forest, and two versions of Support Vector Machines (here svmk and svme). It uses the structure provided by package dismo for model evaluation and projects the models into other sets of environmental variables. A function to join individual partitions in several ways is provided in final_model(). Finally, ensemble_model() assembles models from distinct algorithms and provides summary rasters.">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="index.html">modleR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="articles/modleR.html">Get started</a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">

<div id="modler-a-workflow-for-ecological-niche-models-based-on-dismo" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#modler-a-workflow-for-ecological-niche-models-based-on-dismo" class="anchor"></a>modleR: a workflow for ecological niche models based on dismo</h1></div>
<p><strong>modleR</strong> is a workflow based on package <strong>dismo</strong> (Hijmans et al 2017), designed to automatize some of the common steps when performing ecological niche models. Given the occurrence records and a set of environmental predictors, it prepares the data by cleaning for duplicates, removing occurrences with no environmental information and applying some geographic and environmental filters. It executes crossvalidation or bootstrap procedures, then it performs ecological niche models using several algorithms, some of which are already implemented in the <code>dismo</code> package, and others come from other packages in the R environment, such as glm, Support Vector Machines and Random Forests.</p>
</div>
<div id="installing" class="section level1">
<h1 class="hasAnchor">
<a href="#installing" class="anchor"></a>Installing</h1>
<p>Currently <strong>modleR</strong> can be installed from github:</p>
<pre><code><a href="https://rdrr.io/pkg/remotes/man/install_github.html"># Without vignette
remotes::install_github("Model-R/modleR", build = TRUE)
# With vignette
remotes::install_github("Model-R/modleR", build = TRUE,
                        build_opts = c("--no-resave-data", "--no-manual"))
</a></code></pre>
<p>(<strong>Note regarding vignette building</strong>: the default parameters in <code>build_opts</code> include <code>--no-build-vignettes</code>. Removing this will include this vignette on the installation. During installation, R may ask for some missing packages, which you can install by running <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code>. Also, make sure that the maxent.jar file is available and in the java folder of dismo package. Please download it here: <a href="http://www.cs.princeton.edu/~schapire/maxent/" class="uri">http://www.cs.princeton.edu/~schapire/maxent/</a>)</p>
</div>
<div id="shiny-app" class="section level1">
<h1 class="hasAnchor">
<a href="#shiny-app" class="anchor"></a>Shiny app</h1>
<p>A shiny application currently available at: <a href="https://github.com/Model-R/modleR_shiny_app" class="uri">https://github.com/Model-R/modleR_shiny_app</a> uses a previous version of this workflow and is currently being updated to this newest version.</p>
</div>
<div id="the-workflow" class="section level1">
<h1 class="hasAnchor">
<a href="#the-workflow" class="anchor"></a>The workflow</h1>
<p>The workflow consists of mainly four functions that should be used sequentially.</p>
<p><img src="articles/workflow.png" alt="modleR workflow"></p>
<ol>
<li>Setup: <code>setup_sdmdata()</code> prepares and cleans the data, samples the pseudoabsences, and organizes the experimental design (bootstrap, crossvalidation or repeated crossvalidation). It creates a metadata file with details for the current round and a sdmdata file with the data used for modeling</li>
<li>Model fitting and projecting: <code>do_any()</code> makes the ENM for one algorithm and partition; optionally, <code>do_many()</code> calls <code>do_any()</code> to fit multiple algorithms</li>
<li>Partition joining: <code>final_model()</code> selects or weighs (optionally) the partition models and joins them into a model per species per algorithm</li>
<li>Ensemble: <code>ensemble_model()</code> joins the different models per algorithm into an ensemble model (algorithmic consensus)</li>
</ol>
<div id="folder-structure-created-by-this-package" class="section level2">
<h2 class="hasAnchor">
<a href="#folder-structure-created-by-this-package" class="anchor"></a>Folder structure created by this package</h2>
<p><strong>modleR</strong> writes the outputs in the hard disk, according to the following folder structure:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode R"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="st">`</span><span class="dt">models_dir/projection1/data_setup</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="st">`</span><span class="dt">models_dir/projection1/partitions</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="st">`</span><span class="dt">models_dir/projection1/final_models</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="st">`</span><span class="dt">models_dir/projection1/ensemble_models</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="st">`</span><span class="dt">models_dir/projection2/data_setup</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="st">`</span><span class="dt">models_dir/projection2/partitions</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="st">`</span><span class="dt">models_dir/projection2/final_models</span><span class="st">`</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="st">`</span><span class="dt">models_dir/projection2/ensemble_models</span><span class="st">`</span></a></code></pre></div>
<ul>
<li>We define a <em>partition</em> as the individual modeling round that takes part of the data to train the algorithms and the rest of the data to test them.</li>
<li>We define the <em>final models</em> as joining together the partitions and obtaining <strong>one model per species per algorithm</strong>.</li>
<li>
<em>Ensemble</em> models join together the results obtained by different algorithms (Araújo &amp; New 2007).</li>
<li>When projecting models into the present, the projection folder is called <code>present</code>.</li>
<li>You can set <code>models_dir</code> wherever you want in the hard disk, but if you do not modify the default value, it will create the output under the working directory (its default value is <code>./models</code>, where the period points to the working directory)</li>
<li>The <em>names</em> of the <code>final</code> and <code>ensemble</code> folders can be modified, but <strong>the nested subfolder structure will remain the same</strong>. If you change <code>final_models</code> default value (<code>"final_model"</code>) you will need to include the new value when calling <code>ensemble_model()</code> (<code>final_dir = "[new name]"</code>), to indicate the function where to look for models. This partial flexibility allows for experimenting with final model and ensemble construction (by runnning final or ensemble twice in different output folders, for example).</li>
</ul>
</div>
<div id="cleaning-and-setting-up-the-data-setup_sdmdata" class="section level2">
<h2 class="hasAnchor">
<a href="#cleaning-and-setting-up-the-data-setup_sdmdata" class="anchor"></a>Cleaning and setting up the data: <code>setup_sdmdata()</code>
</h2>
<p>The first step of the workflow is to setup the data, that is, to partition it according to each project needs, to sample background pseudoabsences and to apply some data cleaning procedures, as well as some filters. This is done by function <code>setup_sdmdata()</code></p>
<p><strong>modleR</strong> comes with example data, a data frame called <code>coordenadas</code>, with occurrence data for four species, and predictor variables called <code>example_vars</code></p>
<p><code>{r lib, echo = T, eval = T} #library(modleR) devtools::load_all() # for development #library(raster) str(coordenadas) species &lt;- names(coordenadas) species</code></p>
<p><code>{r dataset, fig.width= 5, fig.height=5, fig.cap= "Figure 1. The example dataset: predictor variables and occurrence for four species.", eval = T} par(mfrow = c(2, 2)) for (i in 1:length(coordenadas)) {   plot(!is.na(example_vars[[1]]), legend = F, main = species[i])   points(lat ~ lon, data = coordenadas[[i]])   } par(mfrow = c(1, 1))</code></p>
<p>We will filter the <code>coordenadas</code> file to select only the data for the first species:</p>
<p><code>{r occs, message = F, eval = TRUE} occs &lt;- coordenadas[[1]]</code></p>
<p><code>setupsdmdata()</code> has a large number of parameters:</p>
<p><code>{r args_setup_sdmdata, eval = T} args(setup_sdmdata)</code></p>
<ul>
<li>
<code>species_name</code> is the name of the species to model</li>
<li>
<code>occurrences</code> is the dataframe with occurrences, lat and lon are the names of the columns for latitude and longitude, respectively. If they are already named <code>lat</code> and <code>lon</code> they need not be specified.</li>
<li>
<code>predictors</code>: is the rasterStack of the environmental variables</li>
</ul>
<p>There are a couple options for data cleaning:</p>
<ul>
<li>
<code>clean_dupl</code> will delete exact duplicates in the occurrence data</li>
<li>
<code>clean_nas</code> will delete any occurrence with no environmental data in the predictor set.</li>
</ul>
<p>The function also sets up different experimental designs:</p>
<ul>
<li>
<code>partition_type</code> can be either bootstrap or k-fold crossvalidation</li>
<li>
<code>boot_n</code> and <code>cv_n</code> perform repeated bootstraps and repeated k-fold crossvalidation, respectively</li>
<li>
<code>boot_proportion</code> sets the proportion of data to be sampled as training set (defaults to 0.8)</li>
<li>
<code>cv_partitions</code> sets the number of partitions in the k-fold crossvalidations (defaults to 3)</li>
<li>but overwrites part when n &lt; 10, setting part to the number of occurrence records (a jacknife partition).</li>
</ul>
<p>Pseudoabsence sampling has also some options:</p>
<ul>
<li>
<code>real_absences</code> can be used to specify a set of user-defined absences, with species name, lat and lon columns.</li>
<li>
<code>geo_filt</code> will eliminate records that are at less than <code>geo_filt_dist</code> between them, in order to control for spatial autocorrelation</li>
<li><p><code>buffer_type</code>: can build a distance buffer around the occurrence points, by taking either the maximal, median or mean distance between points. Pseudoabsence points will be sampled (using <code><a href="https://rdrr.io/pkg/dismo/man/randomPoints.html">dismo::randomPoints()</a></code>) <em>within</em> this buffer, in order to control for the area accessible to the species (M in the BAM diagram).</p></li>
<li><p><code>seed</code>: for reproducilibity purposes</p></li>
</ul>
<p><code>{r sdmdata1sp, eval = T} test_folder &lt;- "~/modleR_test" sdmdata_1sp &lt;- setup_sdmdata(species_name = species[1],                              occurrences = occs,                              predictors = example_vars,                              models_dir = test_folder,                              partition_type = "crossvalidation",                              cv_partitions = 5,                              cv_n = 1,                              seed = 512,                              buffer_type = "mean",                              plot_sdmdata = T,                              n_back = 500,                              clean_dupl = F,                              clean_uni = F,                              clean_nas = F,                              geo_filt = F,                              geo_filt_dist = 10,                              select_variables = T,                              percent = 0.5,                              cutoff = 0.7                              )</code></p>
<ul>
<li>The function will return a <code>sdmdata</code> data frame, with the groups for training and test in bootstrap or crossvalidation, a <code>pa</code> vector that marks presences and absences, and the environmental dataset. This same dataframe will be written in the hard disk, as <code>sdmdata.txt</code>
</li>
<li>It will also write a <code>metadata.txt</code> with the parameters of the latest modeling round. If there has been a cleaning step, it will show different values in the “original.n” and “final.n” columns.</li>
<li>
<strong>NOTE:</strong> <code>setup_sdmdata</code> will check if there’s a prior folder structure and <code>sdmdata.txt</code> and <code>metadata.txt</code> files, in order to avoid repeating the data partitioning.
<ul>
<li>If a call to the function encounters previously written metadata, it will check if the current round has the same parameters and skip the data partitioning. A message will be displayed: <code>#&gt; metadata file found, checking metadata</code> <code>#&gt; same metadata, no need to run data partition</code>
</li>
<li>If a previous metadata file is found but it has different metadata (i.e. there is an inconsistency between the existing metadata and the current parameters), it will run the function with the current parameters.</li>
</ul>
</li>
</ul>
</div>
<div id="fitting-a-model-per-partition-do_any-and-do_many" class="section level2">
<h2 class="hasAnchor">
<a href="#fitting-a-model-per-partition-do_any-and-do_many" class="anchor"></a>Fitting a model per partition: <code>do_any()</code> and <code>do_many()</code>
</h2>
<p>Functions <code>do_any</code> and <code>do_many()</code> create a <em>model per partition, per algorithm</em>. The difference between these functions that <code>do_any()</code> performs modeling for one individual algorithm at a time, that can be chosen by using parameter <code>algorithm</code>, while <code>do_many()</code> can select multiple algorithms, with TRUE or FALSE statements (just as BIOMOD2 functions do).</p>
<p>The available algorithms are:</p>
<ul>
<li>
<code>"bioclim"</code>, <code>"maxent"</code>, <code>"mahal"</code>, <code>"domain"</code>, as implemented in <strong>dismo</strong> package (Hijmans et al 2017),</li>
<li>Support Vector Machines (SVM), as implemented by packages <strong>kernlab</strong> (<code>svmk</code> Karatzoglou et al. 2004] and <strong>e1071</strong> (<code>svme</code> Meyer et al. 2017),</li>
<li>GLM from base R, here implemented with a stepwise selection approach</li>
<li>Random Forests (from package <strong>randomForest</strong> @liaw_classification_2002)</li>
<li>Boosted regression trees (BRT) as implemented by <code>gbm.step()</code> function in <strong>dismo</strong> package (Hastie et al. 2001, Elith &amp; Hijmans 2009).</li>
</ul>
<p>Details for the implementation of each model can be accessed in the documentation of the function.</p>
<p>Here you can see the differences between the parameters of both functions. <code>do_many()</code> calls several instances of <code>do_any()</code> In practice you may only want to call <code>do_many()</code> but for parallelization by algorithm it may be better to call <code>do_any()</code> individually.</p>
<p><code>{r args_do_any_do_many, eval = T} args(do_any) args(do_many)</code></p>
<p>Calling <code>do_many()</code> and setting <code>bioclim = TRUE</code> is therefore equivalent to call <code>do_any()</code> and set <code>algorithm = "bioclim"</code>.</p>
<p>```{r do_any, echo = T, eval = T} sp_maxent &lt;- do_any(species_name = species[1], algorithm = “maxent”, predictors = example_vars, models_dir = test_folder, write_png = T, write_bin_cut = F, equalize = T)</p>
<p>sp_maxent ```</p>
<p>The following lines call for bioclim, GLM, maxent, random forests and smvk (from package <strong>kernlab</strong>)</p>
<p><code>{r do_many, echo = T, eval = T} many &lt;- do_many(species_name = species[1],                 predictors = example_vars,                 models_dir = test_folder,                 write_png = T,                 write_bin_cut = F,                 bioclim = T,                 domain = F,                 glm = T,                 svmk = T,                 svme = T,                 maxent = T,                 maxnet = T,                 rf = T,                 mahal = F,                 brt = T,                 equalize = T)</code></p>
<p>In addition:</p>
<ul>
<li>
<code>mask</code>: will crop and mask the partition models into a ShapeFile</li>
<li>
<code>write_png</code> will create a png file of the output</li>
</ul>
<p>You can explore the list of files created at this phase, for example:</p>
<p><code>{r partfiles} partitions.folder &lt;-      list.files(test_folder, recursive = T,                 pattern = "partitions",                 include.dirs = T, full.names = T) partitions.folder</code></p>
<p>A call to:</p>
<pre><code><a href="https://rdrr.io/r/base/list.files.html">list.files(partitions.folder, recursive = T)</a></code></pre>
<p>should return something like this:</p>
<pre><code>[1] "bioclim_bin_Abarema_langsdorffii_1_1.png"
[2] "bioclim_bin_Abarema_langsdorffii_1_1.tif"
[3] "bioclim_bin_Abarema_langsdorffii_1_2.png"
[4] "bioclim_bin_Abarema_langsdorffii_1_2.tif"
 ...
[11] "bioclim_cont_Abarema_langsdorffii_1_1.png"
[12] "bioclim_cont_Abarema_langsdorffii_1_1.tif"
[13] "bioclim_cont_Abarema_langsdorffii_1_2.png"
[14] "bioclim_cont_Abarema_langsdorffii_1_2.tif"
...
[31] "evaluate_Abarema_langsdorffii_1_1_bioclim.txt"
[32] "evaluate_Abarema_langsdorffii_1_1_glm.txt"
[33] "evaluate_Abarema_langsdorffii_1_1_maxent.txt"
...
[116] "metadata.txt"
...
[145] "rf_cut_Abarema_langsdorffii_1_5.png"
[146] "rf_cut_Abarema_langsdorffii_1_5.tif"
[147] "sdmdata_Abarema_langsdorffii.png"
[148] "sdmdata.txt"</code></pre>
<p>At the end of a modeling round, the partition folder containts:</p>
<ul>
<li>A <code>.tif</code> file for each partition, continuous, binary and cut by the threshold that maximizes its TSS. Its name will indicate the algorithm, the type of model (cont, bin or cut), the name of the species, the run and partition.</li>
<li>Figures in <code>.png</code> to explore the results readily, without reloading them into R or opening them in a SIG program. The creation of these figures can be controlled with the <code>write_png</code> parameter.</li>
<li>A <code>.txt</code> table with the evaluation data for each partition: <code>evaluate_[Species name ]_[partition number]_[algorithm].txt</code>. These files will be read by the <code>final_model()</code> function, to generate the final model per species.</li>
<li>A file called <code>sdmdata.txt</code> with the data used for each partition</li>
<li>A file called <code>metadata.txt</code> with the metadata of the current modeling round.</li>
<li>An optional <code>.png</code> image of the data (controlled by parameter <code>plot_sdmdata = T</code>)</li>
</ul>
</div>
<div id="joining-partitions-final_model" class="section level2">
<h2 class="hasAnchor">
<a href="#joining-partitions-final_model" class="anchor"></a>Joining partitions: <code>final_model()</code>
</h2>
<p>There are many ways to create a final model per algorithm per species. <code>final_model()</code> follows the following logic:</p>
<p><img src="articles/final_model_english.png" alt="final_model() options">{ width=75% }</p>
<ul>
<li>It can select the best partitions if the parameter <code>select.partitions = TRUE</code>, selecting only those who obtained a TSS value above <code>TSS.value</code> (TSS varies between -1 and 1, defaults to 0.7). If <code>select.partitions</code> is set to FALSE, no selection will be performed and it will use all the partitions.</li>
<li>The selected partitions can be the raw, uncut models, the binary or the cut (zero below the threshold and continuous above it) and form a <code>raster::rasterStack()</code> object.</li>
<li>Their means can be calculated (<code>raw_mean</code>, <code>bin_mean</code> or <code>cut_mean</code>, second line in Figure 2)</li>
<li>From <code>raw_mean</code>, a binary model can be obtained by cutting it by the mean threshold that maximizes the selected performance metric for each partition (<code>bin_mean_th</code>). A “cut” model can also be obtained (<code>cut_mean_th</code>).</li>
<li>From <code>bin_mean</code>, a consensus model (i.e. how many of the retained models predict an area) can be built (<code>bin_consensus</code>). The parameter <code>consensus_level</code> allows to set this level of consensus (defaults to 0.5: majority consensus approach).</li>
<li>NOTE: The final models can be done using a subset of the algorithms avaliable on the hard disk, using the parameter <code>algorithms</code>. If left unspecified, all algorithms listed in the <code>evaluate</code> files will be used.</li>
</ul>
<p><code>{r final_model, eval = T} args(final_model)</code></p>
<p><code>{r final, echo = T, eval = T} final_model(species_name = species[1],             algorithms = NULL, #if null it will take all the in-disk algorithms             models_dir = test_folder,             select_partitions = TRUE,             select_par = "TSS",             select_par_val = 0,             which_models = c("raw_mean", "bin_consensus"),             consensus_level = 0.5,             uncertainty = T,             overwrite = T)</code></p>
<p><code>final_model()</code> creates a .tif file for each final.model (one per algorithm) under the specified folder (default: <code>final_models</code>)</p>
<p>We can explore these models from the files:</p>
<p><code>{r final_folder, eval = T} final.folder &lt;- list.files(test_folder,                            recursive = T,                            pattern = "final_models",                            include.dirs = T,                            full.names = T) final.folder final_mods &lt;- list.files(final.folder, full.names = T, pattern = "raw_mean.+tif$", recursive = T) final_mods</code></p>
<p>```{r plot_final, fig.width = 7, fig.height = 6, eval = T} final_models &lt;- stack(final_mods)</p>
<p>names(final_models) &lt;- sapply(strsplit(names(final_models), paste0(species[1], ’_’)), function(x) x[2]) plot(final_models) ```</p>
</div>
<div id="ensemble_model" class="section level2">
<h2 class="hasAnchor">
<a href="#ensemble_model" class="anchor"></a>ensemble_model()</h2>
<p>The fourth step of the workflow is joining the models for each algorithm into a final ensemble model. <code>ensemble_model()</code> calculates the mean, standard deviation, minimum and maximum values of the final models and saves them under the folder specified by <code>ensemble_dir</code>. It can also create these models by a consensus rule (what proportion of final models predict a presence in each pixel, 0.5 is a majority rule, 0.3 would be 30% of the models).</p>
<p><code>ensemble_model()</code> uses the same <code>which.model</code> parameter of the <code>final_model()</code> function to specify which final model (Figure 2) should be assembled together (the default is a mean of the raw continuous models: <code>which.models = c("raw_mean")</code>).</p>
<p><code>{r ensemble_model, eval = T} args(ensemble_model) ens &lt;- ensemble_model(species[1],                occurrences = occs,                which_final = "raw_mean",                models_dir = test_folder,                overwrite = TRUE) #argument from writeRaster</code></p>
<p>At any point we can explore the outputs in the folders:</p>
<p>```{r check_ensemble, fig.width = 5, fig.height = 5, eval= T} ensemble_files &lt;- list.files(paste0(test_folder,“/”, species[1],“/present/ensemble”), recursive = T, pattern = “raw_mean.+tif$”, full.names = T)</p>
<p>ensemble_files ens_mod &lt;- stack(ensemble_files) names(ens_mod) &lt;- c(“mean”, “median”, “range”, “st.dev”) plot(ens_mod) ```</p>
</div>
</div>
<div id="workflows-with-multiple-species" class="section level1">
<h1 class="hasAnchor">
<a href="#workflows-with-multiple-species" class="anchor"></a>Workflows with multiple species</h1>
<p>Our <code>coordenadas</code> dataset has data for four species. An option to do the several models is to use a <code>for</code> loop</p>
<p>```{r forloop, eval = F} args(do_many) args(setup_sdmdata)</p>
<p>for (i in 1:length(coordenadas)) { sp &lt;- species[i] occs &lt;- coordenadas[[i]] setup_sdmdata( species_name = sp, models_dir = “~/modleR_test/forlooptest”, occurrences = occs, predictors = example_vars, buffer_type = “distance”, dist_buf = 4, write_buffer = T, clean_dupl = T, clean_nas = T, clean_uni = T, plot_sdmdata = T, n_back = 1000, partition_type = “bootstrap”, boot_n = 5, boot_proportion = 0.7 ) }</p>
<p>for (i in 1:length(coordenadas)) { sp &lt;- species[i] do_many(species_name = sp, predictors = example_vars, models_dir = “~/modleR_test/forlooptest”, write_png = T, bioclim = T, maxent = T, maxnet = F, rf = T, svmk = T, svme = T, brt = T, glm = T, domain = F, mahal = F, equalize = T, write_bin_cut = T) }</p>
<p>for (i in 1:length(coordenadas)) { sp &lt;- species[i] final_model(species_name = sp, select_partitions = TRUE, select_par = “TSS”, select_par_val = 0.5, consensus_level = 0.5, models_dir = “~/modleR_test/forlooptest”, which_models = c(“raw_mean”, “bin_consensus”), uncertainty = T, overwrite = T) }</p>
<p>for (i in 1:length(coordenadas)) { sp &lt;- species[i] occs &lt;- coordenadas[[i]] ensemble_model(species_name = sp, occurrences = occs, which_final = “bin_consensus”, write_ensemble = T, models_dir = “~/modleR_test/forlooptest”) } ```</p>
<p>Another option is to use the <code>purrr</code> package (Henry &amp; Wickham 2017).</p>
<p>```{r purrr example, eval = F} library(purrr)</p>
<p>coordenadas %&gt;% purrr::map2(.x= ., .y= as.list(names(.)), ~ setup_sdmdata(species_name = .y, occurrences = .x, partition_type = “bootstrap”, boot_n = 5, boot_proportion = 0.7, clean_nas = T, clean_dupl = T, clean_uni = T, buffer_type = “distance”, dist_buf = 4, predictors = example_vars, models_dir = “~/modleR_test/temp_purrr”, n_back = 1000))</p>
<p>species %&gt;% as.list(.) %&gt;% purrr::map(~ do_many(species_name = ., predictors = example_vars, models_dir = “~/modleR_test/temp_purrr”, bioclim = T, maxent = T, rf = T, svme = T, svmk = T, domain = F, glm = T, mahal = F, brt = T, equalize = T)) ```</p>
<p><code>{r purrr_final, eval = F} species %&gt;% as.list(.) %&gt;%   purrr::map(~ final_model(species_name = .,                            select_partitions = TRUE,                            select_par = "TSS",                            select_par_val = 0.5,                            consensus_level = 0.5,                            models_dir = "~/modleR_test/temp_purrr",                            which_models = "raw_mean",                            overwrite = TRUE))</code></p>
<p>```{r purrr_ensemble, eval = F} coordenadas %&gt;% purrr::map2(.x= ., .y= as.list(names(.)), ~ ensemble_model(species_name = .y, occurrences = .x, which_final = “raw_mean”, write_ensemble = T, models_dir = “~/modleR_test/temp_purrr”, overwrite = TRUE))</p>
<p>```</p>
<div id="parallel-computing" class="section level2">
<h2 class="hasAnchor">
<a href="#parallel-computing" class="anchor"></a>Parallel computing</h2>
<p><code>{r remedy001, eval=F} library(parallel)</code></p>
</div>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<p>Araújo, M, and M New. 2007. “Ensemble Forecasting of Species Distributions.” Trends in Ecology &amp; Evolution 22 (1): 42–47. <a href="doi:10.1016/j.tree.2006.09.010" class="uri">doi:10.1016/j.tree.2006.09.010</a>.</p>
<p>Elith, Jane, Catherine H. Graham*, Robert P. Anderson, Miroslav Dudík, Simon Ferrier, Antoine Guisan, Robert J. Hijmans, et al. 2006. “Novel Methods Improve Prediction of Species’ Distributions from Occurrence Data.” Ecography 29 (2): 129–51. <a href="doi:10.1111/j.2006.0906-7590.04596.x" class="uri">doi:10.1111/j.2006.0906-7590.04596.x</a>.</p>
<p>Henry, Lionel, and Hadley Wickham. 2017. Purrr: Functional Programming Tools. R Package Version 0.2.4. <a href="https://CRAN.R-project.org/package=purrr" class="uri">https://CRAN.R-project.org/package=purrr</a>.</p>
<p>Hijmans, Robert J., Steven Phillips, John Leathwick, and Jane Elith. 2017. Dismo: Species Distribution Modeling. R Package Version 1.1-4. <a href="http://CRAN.R-project.org/package=dismo" class="uri">http://CRAN.R-project.org/package=dismo</a>.</p>
<p>Kamino, Luciana Hiromi Yoshino, Marinez Ferreira de Siqueira, Andrea Sánchez-Tapia, and João Renato Stehmann. 2012. “Reassessment of the Extinction Risk of Endemic Species in the Neotropics: How Can Modelling Tools Help Us?” Natureza &amp; Conservação 10 (2): 191–98. <a href="doi:10.4322/natcon.2012.033" class="uri">doi:10.4322/natcon.2012.033</a>.</p>
<p>Karatzoglou, Alexandros, Alex Smola, Kurt Hornik, and Achim Zeileis. 2004. “Kernlab – an S4 Package for Kernel Methods in R.” Journal of Statistical Software 11 (9): 1–20. <a href="http://www.jstatsoft.org/v11/i09/" class="uri">http://www.jstatsoft.org/v11/i09/</a>.</p>
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</p>
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2017. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. <a href="https://CRAN.R-project.org/package=e1071" class="uri">https://CRAN.R-project.org/package=e1071</a>.</p>
<p>Varela, Sara, Robert P. Anderson, Raúl García-Valdés, and Federico Fernández-González. 2014. “Environmental Filters Reduce the Effects of Sampling Bias and Improve Predictions of Ecological Niche Models.” Ecography 37 (11): 1084–91. <a href="doi:10.1111/j.1600-0587.2013.00441.x" class="uri">doi:10.1111/j.1600-0587.2013.00441.x</a>.</p>
</div>

  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <div class="links">
<h2>Links</h2>
<ul class="list-unstyled">
<li>Report a bug at <br><a href="https://github.com/Model-R/modleR/issues">https://​github.com/​Model-R/​modleR/​issues</a>
</li>
</ul>
</div>
<div class="license">
<h2>License</h2>
<ul class="list-unstyled">
<li>GPL (&gt;= 3)</li>
</ul>
</div>
<div class="citation">
<h2>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html">Citing modleR</a></li>
</ul>
</div>
<div class="developers">
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Andrea Sánchez-Tapia <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-3521-4338" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid" alt="ORCID"></a> </li>
<li>Sara Mortara <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0001-6221-7537" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid" alt="ORCID"></a> </li>
<li>Diogo Rocha <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0003-2913-4072" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid" alt="ORCID"></a> </li>
<li>Felipe Barros <br><small class="roles"> Author </small>  </li>
<li>Guilherme Gall <br><small class="roles"> Author </small>  </li>
<li><a href="authors.html">All authors...</a></li>
</ul>
</div>

  </div>
</div>


      <footer><div class="copyright">
  <p>Developed by Andrea Sánchez-Tapia, Sara Mortara, Diogo Rocha, Felipe Barros, Guilherme Gall.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
